{"timestamp":"2025-06-05T00:26:04.246827","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-05T00:26:04.247061","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/reddit_btc_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-05T00:26:04.252738","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:04.253230","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'cd /opt/airflow/user_pipeline && python scripts/daily_pipeline.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:04.263859Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:04.263979Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:04.264053Z","level":"info","event":"Current task name:run_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:04.264104Z","level":"info","event":"Dag name:reddit_btc_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:04.259527","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:05.179203","level":"info","event":"[nltk_data] Error loading vader_lexicon: <urlopen error [Errno -2]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:05.179293","level":"info","event":"[nltk_data]     Name or service not known>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.967714","level":"info","event":"\rReddit posts: 0it [00:00, ?it/s]\rReddit posts: 0it [00:03, ?it/s]","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.975428","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.975610","level":"info","event":"  File \"/opt/airflow/user_pipeline/scripts/daily_pipeline.py\", line 23, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.976312","level":"info","event":"    process_sentiment(\"data/staging/reddit_today.csv\", \"data/staging/reddit_today.csv\")","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.976399","level":"info","event":"  File \"/opt/airflow/user_pipeline/scripts/process_sentiment.py\", line 9, in process_sentiment","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.977103","level":"info","event":"    df = pd.read_csv(input_file)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.977194","level":"info","event":"         ^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.977243","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978421","level":"info","event":"    return _read(filepath_or_buffer, kwds)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978526","level":"info","event":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978577","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 611, in _read","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978621","level":"info","event":"    parser = TextFileReader(filepath_or_buffer, **kwds)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978708","level":"info","event":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978748","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978948","level":"info","event":"    self._engine = self._make_engine(f, self.engine)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.978998","level":"info","event":"                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979037","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1723, in _make_engine","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979391","level":"info","event":"    return mapping[engine](f, **self.options)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979447","level":"info","event":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979484","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979827","level":"info","event":"    self._reader = parsers.TextReader(src, **kwds)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979876","level":"info","event":"                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.979913","level":"info","event":"  File \"parsers.pyx\", line 586, in pandas._libs.parsers.TextReader.__cinit__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:08.980506","level":"info","event":"pandas.errors.EmptyDataError: No columns to parse from file","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:09.096346","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-06-05T00:26:09.096747","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":838,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1130,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":233,"name":"execute"}]}]}
{"timestamp":"2025-06-05T00:26:09.097274Z","level":"info","event":"Task instance in failure state","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:09.097426Z","level":"info","event":"Task start","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:09.097504Z","level":"info","event":"Task:<Task(BashOperator): run_pipeline>","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T00:26:09.097618Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","chan":"stdout","logger":"task"}
