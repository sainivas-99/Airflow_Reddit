{"timestamp":"2025-05-30T23:00:00.907942","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-30T23:00:00.908274","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/reddit_btc_pipeline.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-30T23:00:00.927522Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:00.927663Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:00.927751Z","level":"info","event":"Current task name:check_new_reddit_posts","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:00.927807Z","level":"info","event":"Dag name:reddit_btc_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130090Z","level":"info","event":"STDOUT:","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130310Z","level":"info","event":"STDERR: Traceback (most recent call last):","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130405Z","level":"info","event":"  File \"/opt/airflow/user_pipeline/scripts/check_new_reddit_posts.py\", line 37, in <module>","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130490Z","level":"info","event":"    result = check_for_new_reddit_posts()","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130568Z","level":"info","event":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130648Z","level":"info","event":"  File \"/opt/airflow/user_pipeline/scripts/check_new_reddit_posts.py\", line 28, in check_for_new_reddit_posts","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130713Z","level":"info","event":"    existing_df = pd.read_csv(master_file_path)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130783Z","level":"info","event":"                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130853Z","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130919Z","level":"info","event":"    return _read(filepath_or_buffer, kwds)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130981Z","level":"info","event":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131043Z","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 611, in _read","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131106Z","level":"info","event":"    parser = TextFileReader(filepath_or_buffer, **kwds)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131209Z","level":"info","event":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131313Z","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131391Z","level":"info","event":"    self._engine = self._make_engine(f, self.engine)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131460Z","level":"info","event":"                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131518Z","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1723, in _make_engine","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131584Z","level":"info","event":"    return mapping[engine](f, **self.options)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131659Z","level":"info","event":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131789Z","level":"info","event":"  File \"/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131863Z","level":"info","event":"    self._reader = parsers.TextReader(src, **kwds)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131918Z","level":"info","event":"                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.131986Z","level":"info","event":"  File \"parsers.pyx\", line 586, in pandas._libs.parsers.TextReader.__cinit__","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.132047Z","level":"info","event":"pandas.errors.EmptyDataError: No columns to parse from file","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.132108Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.132206Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.132265Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.132324Z","level":"info","event":"Task operator:<Task(ShortCircuitOperator): check_new_reddit_posts>","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-30T23:00:03.130466","level":"info","event":"Done. Returned value was: False","logger":"airflow.task.operators.airflow.providers.standard.operators.python.ShortCircuitOperator"}
{"timestamp":"2025-05-30T23:00:03.130532","level":"info","event":"Condition result is False","logger":"airflow.task.operators.airflow.providers.standard.operators.python.ShortCircuitOperator"}
{"timestamp":"2025-05-30T23:00:03.130572","level":"info","event":"Skipping downstream tasks","logger":"airflow.task.operators.airflow.providers.standard.operators.python.ShortCircuitOperator"}
{"timestamp":"2025-05-30T23:00:03.130805","level":"info","event":"Skipping downstream tasks.","logger":"task"}
